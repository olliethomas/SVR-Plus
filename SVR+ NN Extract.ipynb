{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rm\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.vq import whiten\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from cvxopt import matrix, solvers\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import operator\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract from my NN assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gaussian():\n",
    "    def __call__(self, a, b, sigma):\n",
    "        x = np.array(a).reshape(1,-1)\n",
    "        y = np.array(b).reshape(1,-2)\n",
    "        return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "    def name(self):\n",
    "        return \"Gaussian\"\n",
    "    \n",
    "class MV_Gaussian():\n",
    "    def __call__(self, a, b, cov):\n",
    "        x = np.array(a)\n",
    "        y = np.array(b)\n",
    "        c = np.array(cov)\n",
    "        return np.exp(-0.5*np.dot(np.dot((x-y).T, np.linalg.inv(c)), (x-y)))\n",
    "    \n",
    "class Linear:\n",
    "    def __call__(self, a, b, sigma):\n",
    "        return np.dot(a,b)\n",
    "    def name(self):\n",
    "        return \"Linear\"\n",
    "    \n",
    "class Polynomial:\n",
    "    def __call__(self, a, b, throwaway, p=2):\n",
    "        self.p = p\n",
    "        x = np.array(a)\n",
    "        y = np.array(b)\n",
    "        y = np.transpose(y)\n",
    "        return (1 + np.dot(x, y)) ** p\n",
    "    def name(self):\n",
    "        return \"Quadratic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = np.genfromtxt ('data118448.csv', delimiter=\",\")\n",
    "np.random.shuffle(csv)\n",
    "csv = csv[:200, :]\n",
    "x = csv[:, :-1]\n",
    "y = csv[:, -1:]\n",
    "for i in range(len(x[0])):\n",
    "    sd = np.std(x[:,i])\n",
    "    mean = np.mean(x[:,i])\n",
    "    for j in range(len(x)):\n",
    "        x[j,i] = (x[j,i]-mean)/sd\n",
    "train_x = np.copy(x[:-100, :])\n",
    "train_y = np.copy(y[:-100, :])\n",
    "top_secret_unseen_x = np.copy(x[-100:, :])\n",
    "top_secret_unseen_y = np.copy(y[-100:, :])\n",
    "\n",
    "# add bias to X once pre-processed\n",
    "ones = np.ones(len(train_x)).reshape(1,-1)\n",
    "train_x = np.concatenate((train_x, ones.T), axis=1)\n",
    "ones = np.ones(len(top_secret_unseen_x)).reshape(1,-1)\n",
    "top_secret_unseen_x = np.concatenate((top_secret_unseen_x, ones.T), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR\n",
    "Support Vector Machines are where it's at. They're cool, so let's try and implement one. But not just any SVR, SVR+ which is mentioned in [this](http://www.sciencedirect.com/science/article/pii/S0893608009001130) paper. Below compares the objective function of each. The plan is to try and be a bit creative and see if we can do something cutting edge... First we're going to build the SVR+. I can't find any implementations online so let's try and build one from just the description. Apologies if the notation is a little confusing, I haven't explicitly said when vectors are column and when they're row (or even when we're talking about matrices!), but this is mostly just to help me work out what I want to do. See the code for a more explicit description.\n",
    "\n",
    "The idea is then that we're going to use the idea of [LuFE](https://www.ijcai.org/Proceedings/16/Papers/294.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard SVR\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{w,b,\\xi, \\xi^*} \\quad & \\frac{1}{2}(w,w)+C\\sum_{i=1}^{\\ell}(\\xi_i + \\xi^*_i) \\\\\n",
    "\\textrm{subject to} \\quad & y_i - (w,x_i) - b \\leq \\epsilon + \\xi_i \\\\\n",
    "\\textrm{and} \\quad & (w,x_i) + b - y_i \\leq \\epsilon + \\xi^*_i \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "### SVR+\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{w, w^*_1, w^*_2,b,b^*_1,b^*_2} \\quad & \\frac{1}{2}[(w,w)+\\gamma[(w^*_1,w^*_1)+(w^*_2,w^*_2)]]+C\\sum_{i=1}^{\\ell}[(w^*_1,x^*_i)+b^*_1]+C\\sum_{i=1}^{\\ell}[(w^*_2,x^*_i)+b^*_2] \\\\\n",
    "\\textrm{subject to} \\quad & y_i - (w,x_i) - b \\leq \\epsilon + (w^*_1,x^*_i)+b^*_1 \\\\\n",
    "\\textrm{and} \\quad & (w,x_i) + b - y_i \\leq \\epsilon + (w^*_2, x^*_i)+b^*_2 \\\\\n",
    "\\textrm{and} \\quad & [(w^*_1,x^*_i)+b^*_1] \\geq 0 \\\\\n",
    "\\textrm{and} \\quad & [(w^*_2,x^*_i)+b^*_2] \\geq 0 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR+ Dual Form\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max_{\\alpha, \\alpha^*, \\beta, \\beta^*} \\quad & \\sum_{i=1}^{\\ell} y_i(\\alpha^*_i - \\alpha_i) - \\epsilon \\sum_{i=1}^{\\ell}(\\alpha_i + \\alpha_i^*) \\\\\n",
    "& - \\frac{1}{2}\\sum_{i,j=1}^{\\ell}(\\alpha^*_i - \\alpha_i)(\\alpha^*_j - \\alpha_j) K(x_i,x_j)\\\\\n",
    "& - \\frac{1}{2\\gamma}\\sum_{i,j=1}^{\\ell}(\\alpha_i^* + \\beta_i^* -C)(\\alpha_j^* + \\beta_j^* -C) K^*(x^*_i , x^*_j) \\\\\n",
    "& - \\frac{1}{2\\gamma}\\sum_{i,j=1}^{\\ell}(\\alpha_i + \\beta_i -C)(\\alpha_j + \\beta_j -C) K^*(x^*_i , x^*_j) \\\\\n",
    "\\textrm{subject to} \\quad & \\sum_{i=1}^{\\ell}\\alpha_i^* = \\sum_{i=1}^{\\ell}\\alpha_i \\\\\n",
    "\\textrm{and} \\quad & \\sum_{i=1}^{\\ell} (\\alpha^*_i + \\beta_i^* - C) = 0 \\\\\n",
    "\\textrm{and} \\quad & \\sum_{i=1}^{\\ell} (\\alpha_i + \\beta_i - C) = 0 \\\\\n",
    "\\textrm{and} \\quad & \\alpha \\geq 0, \\quad \\alpha^* \\geq 0, \\quad \\beta \\geq 0, \\quad \\beta^* \\geq 0\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll solve this using CVXOPT, which solves problems in the form \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{x} \\quad & \\frac{1}{2}x^TPx + q^Tx \\\\\n",
    "\\textrm{subject to} \\quad & Gx \\leq h \\\\\n",
    "& Ax = b\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "So let's put the SVR Dual Form in the correct structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In CVXOPT Form\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\alpha, \\alpha^*, \\beta, \\beta^*} \\quad & \\epsilon \\sum_{i=1}^{\\ell}(\\alpha_i + \\alpha_i^*) - \\sum_{i=1}^{\\ell} y_i(\\alpha^*_i - \\alpha_i) \\\\\n",
    "& + \\frac{1}{2}\\sum_{i,j=1}^{\\ell}(\\alpha^*_i - \\alpha_i)(\\alpha^*_j - \\alpha_j) K(x_i,x_j)\\\\\n",
    "& + \\frac{1}{2\\gamma}\\sum_{i,j=1}^{\\ell}(\\alpha_i^* + \\beta_i^* -C)(\\alpha_j^* + \\beta_j^* -C) K^*(x^*_i , x^*_j) \\\\\n",
    "& + \\frac{1}{2\\gamma}\\sum_{i,j=1}^{\\ell}(\\alpha_i + \\beta_i -C)(\\alpha_j + \\beta_j -C) K^*(x^*_i , x^*_j) \\\\\n",
    "\\textrm{subject to} \\quad & \\sum_{i=1}^{\\ell}\\alpha_i^* - \\sum_{i=1}^{\\ell}\\alpha_i = 0 \\\\\n",
    "\\textrm{and} \\quad & \\sum_{i=1}^{\\ell} (\\alpha^*_i + \\beta_i^* - C) = 0 \\\\\n",
    "\\textrm{and} \\quad & \\sum_{i=1}^{\\ell} (\\alpha_i + \\beta_i - C) = 0 \\\\\n",
    "\\textrm{and} \\quad & -\\alpha \\leq 0, \\quad -\\alpha^* \\leq 0, \\quad -\\beta \\leq 0, \\quad -\\beta^* \\leq 0\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Variables\n",
    "By denoting $\\delta = \\beta - C$ we can describe the variable to find, $x$, as\n",
    "\n",
    "$$ x = \n",
    "\\begin{pmatrix}\n",
    "\\alpha \\\\ \\alpha^* \\\\ \\delta \\\\ \\delta^*\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Objective\n",
    "\n",
    "$$\n",
    "P = \n",
    "\\begin{pmatrix}\n",
    "(K(x_i,x_j) + \\gamma K^*(x^*_i,x^*_j)) & -K(x_i,x_j) & \\gamma K^*(x^*_i,x^*_j) & \\textbf{0} \\\\\n",
    "- K(x_i,x_j) & (K(x_i,x_j) + \\gamma K^*(x^*_i,x^*_j)) & \\textbf{0} & \\gamma K^*(x^*_i,x^*_j) \\\\\n",
    "\\gamma K^*(x^*_i,x^*_j) & \\textbf{0} & \\gamma K^*(x^*_i,x^*_j) & \\textbf{0} \\\\\n",
    "\\textbf{0} & \\gamma K^*(x^*_i,x^*_j) & \\textbf{0} & \\gamma K^*(x^*_i,x^*_j)\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "q = \n",
    "\\begin{pmatrix}\n",
    "(\\textbf{Y}+\\epsilon ) \\\\ (-\\textbf{Y}+\\epsilon ) \\\\ \\textbf{0} \\\\ \\textbf{0}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\min_{\\alpha, \\alpha^*, \\delta, \\delta^*} \n",
    "\\begin{pmatrix}\n",
    "\\alpha \\\\ \\alpha^* \\\\ \\delta \\\\ \\delta^*\n",
    "\\end{pmatrix}^T\n",
    "\\begin{pmatrix}\n",
    "(K(x_i,x_j) + \\gamma K^*(x^*_i,x^*_j)) & -K(x_i,x_j) & \\gamma K^*(x^*_i,x^*_j) & \\textbf{0} \\\\\n",
    "- K(x_i,x_j) & (K(x_i,x_j) + \\gamma K^*(x^*_i,x^*_j)) & \\textbf{0} & \\gamma K^*(x^*_i,x^*_j) \\\\\n",
    "\\gamma K^*(x^*_i,x^*_j) & \\textbf{0} & \\gamma K^*(x^*_i,x^*_j) & \\textbf{0} \\\\\n",
    "\\textbf{0} & \\gamma K^*(x^*_i,x^*_j) & \\textbf{0} & \\gamma K^*(x^*_i,x^*_j)\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\\alpha \\\\ \\alpha^* \\\\ \\delta \\\\ \\delta^*\n",
    "\\end{pmatrix}\n",
    "+\n",
    "\\begin{pmatrix}\n",
    "(\\textbf{Y}+\\epsilon ) \\\\ (-\\textbf{Y}+\\epsilon ) \\\\ \\textbf{0} \\\\ \\textbf{0}\n",
    "\\end{pmatrix}^T\n",
    "\\begin{pmatrix}\n",
    "\\alpha \\\\ \\alpha^* \\\\ \\delta \\\\ \\delta^*\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Inequalities\n",
    "\n",
    "$$\n",
    "G = \n",
    "\\begin{pmatrix}\n",
    "\\textbf{-I} & \\textbf{0} & \\textbf{0} & \\textbf{0} \\\\\n",
    "\\textbf{0} & \\textbf{-I} & \\textbf{0} & \\textbf{0} \\\\\n",
    "\\textbf{0} & \\textbf{0} & \\textbf{-I} & \\textbf{0} \\\\\n",
    "\\textbf{0} & \\textbf{0} & \\textbf{0} & \\textbf{-I}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "h =\n",
    "\\begin{pmatrix}\n",
    "\\textbf{0} \\\\\n",
    "\\textbf{0} \\\\\n",
    "\\textbf{C} \\\\\n",
    "\\textbf{C}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\textbf{-I} & \\textbf{0} & \\textbf{0} & \\textbf{0} \\\\\n",
    "\\textbf{0} & \\textbf{-I} & \\textbf{0} & \\textbf{0} \\\\\n",
    "\\textbf{0} & \\textbf{0} & \\textbf{-I} & \\textbf{0} \\\\\n",
    "\\textbf{0} & \\textbf{0} & \\textbf{0} & \\textbf{-I}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\\alpha \\\\ \\alpha^* \\\\ \\delta \\\\ \\delta^*\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\textbf{0} \\\\\n",
    "\\textbf{0} \\\\\n",
    "\\textbf{C} \\\\\n",
    "\\textbf{C}\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Equalities\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "\\textbf{-1} & \\textbf{1} & \\textbf{0} & \\textbf{0} \\\\\n",
    "\\textbf{1} & \\textbf{0} & \\textbf{1} & \\textbf{0} \\\\\n",
    "\\textbf{0} & \\textbf{1} & \\textbf{0} & \\textbf{1} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = \n",
    "\\begin{pmatrix}\n",
    "0 \\\\ 0 \\\\ 0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\textbf{-1} & \\textbf{1} & \\textbf{0} & \\textbf{0} \\\\\n",
    "\\textbf{1} & \\textbf{0} & \\textbf{1} & \\textbf{0} \\\\\n",
    "\\textbf{0} & \\textbf{1} & \\textbf{0} & \\textbf{1} \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\\alpha \\\\ \\alpha^* \\\\ \\delta \\\\ \\delta^*\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "0 \\\\ 0 \\\\ 0\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVR:\n",
    "    def train(self, X, Xstar, Y, C, epsilon, gamma, kern):\n",
    "        self.training_X = X\n",
    "        self.Y = Y\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        self.kern_x = kern\n",
    "        \n",
    "        self.sigma = 0\n",
    "        if kern.name() == \"Gaussian\":\n",
    "            sqd = np.zeros((len(X), len(X)))\n",
    "            for i in range(len(X)):\n",
    "                for j in range(len(X)):\n",
    "                    sqd[i, j] = np.linalg.norm(X[i] - X[j])\n",
    "            self.sigma = np.median(sqd)\n",
    "        \n",
    "        x_i_x_j = self.gram(X, X, kern, self.sigma)\n",
    "        x_star_i_x_star_j = self.gram(Xstar, Xstar, Polynomial(), self.sigma)\n",
    "        \n",
    "        p00 = x_i_x_j + gamma*x_star_i_x_star_j\n",
    "        p01 = -x_i_x_j\n",
    "        p02 = gamma*x_star_i_x_star_j\n",
    "        p03 = np.zeros((len(X), len(X)))\n",
    "        p10 = -x_i_x_j\n",
    "        p11 = x_i_x_j + gamma*x_star_i_x_star_j\n",
    "        p12 = np.zeros((len(X), len(X)))\n",
    "        p13 = gamma*x_star_i_x_star_j\n",
    "        p20 = gamma*x_star_i_x_star_j\n",
    "        p21 = np.zeros((len(X), len(X)))\n",
    "        p22 = gamma*x_star_i_x_star_j\n",
    "        p23 = np.zeros((len(X), len(X)))\n",
    "        p30 = np.zeros((len(X), len(X)))\n",
    "        p31 = gamma*x_star_i_x_star_j\n",
    "        p32 = np.zeros((len(X), len(X)))\n",
    "        p33 = gamma*x_star_i_x_star_j\n",
    "        \n",
    "        p0 = np.hstack((p00, p01))\n",
    "        p0 = np.hstack((p0, p02))\n",
    "        p0 = np.hstack((p0, p03))\n",
    "\n",
    "        p1 = np.hstack((p10, p11))\n",
    "        p1 = np.hstack((p1, p12))\n",
    "        p1 = np.hstack((p1, p13))\n",
    "        \n",
    "        p2 = np.hstack((p20, p21))\n",
    "        p2 = np.hstack((p2, p22))\n",
    "        p2 = np.hstack((p2, p23))\n",
    "        \n",
    "        p3 = np.hstack((p30, p31))\n",
    "        p3 = np.hstack((p3, p32))\n",
    "        p3 = np.hstack((p3, p33))\n",
    "        \n",
    "        p = np.vstack((p0, p1))\n",
    "        p = np.vstack((p, p2))\n",
    "        p = np.vstack((p, p3))\n",
    "        \n",
    "        q0 = Y.reshape(1,-1)+epsilon\n",
    "        q1 = -Y.reshape(1,-1)+epsilon\n",
    "        q = np.hstack((q0, q1))\n",
    "        q = np.hstack((q, np.zeros(len(X)).reshape(1,-1)))\n",
    "        q = np.hstack((q, np.zeros(len(X)).reshape(1,-1)))\n",
    "        q = q.T\n",
    "        \n",
    "        g0 = -np.eye(len(X))\n",
    "        g0 = np.hstack((g0, np.zeros((len(X), len(X)))))\n",
    "        g0 = np.hstack((g0, np.zeros((len(X), len(X)))))\n",
    "        g0 = np.hstack((g0, np.zeros((len(X), len(X)))))\n",
    "        h0 = np.zeros(len(X)).reshape(-1,1)\n",
    "        \n",
    "        g1 = np.zeros((len(X), len(X)))\n",
    "        g1 = np.hstack((g1, -np.eye(len(X))))\n",
    "        g1 = np.hstack((g1, np.zeros((len(X), len(X)))))\n",
    "        g1 = np.hstack((g1, np.zeros((len(X), len(X)))))\n",
    "        h1 = np.zeros(len(X)).reshape(-1,1)\n",
    "        \n",
    "        g2 = np.zeros((len(X), len(X)))\n",
    "        g2 = np.hstack((g2, np.zeros((len(X), len(X)))))\n",
    "        g2 = np.hstack((g2, -np.eye(len(X))))\n",
    "        g2 = np.hstack((g2, np.zeros((len(X), len(X)))))\n",
    "        h2 = np.repeat(C, len(X)).reshape(-1,1)\n",
    "        \n",
    "        g3 = np.zeros((len(X), len(X)))\n",
    "        g3 = np.hstack((g3, np.zeros((len(X), len(X)))))\n",
    "        g3 = np.hstack((g3, np.zeros((len(X), len(X)))))\n",
    "        g3 = np.hstack((g3, -np.eye(len(X))))\n",
    "        h3 = np.repeat(C, len(X)).reshape(-1,1)\n",
    "        \n",
    "        g = np.vstack((g0,g1))\n",
    "        g = np.vstack((g,g2))\n",
    "        g = np.vstack((g,g3))\n",
    "        \n",
    "        h = np.vstack((h0,h1))\n",
    "        h = np.vstack((h,h2))\n",
    "        h = np.vstack((h,h3))\n",
    "        \n",
    "        a0 = np.hstack((-np.ones(len(X)), np.ones(len(X))))\n",
    "        a0 = np.hstack((a0, np.zeros(len(X))))\n",
    "        a0 = np.hstack((a0, np.zeros(len(X))))\n",
    "        b0 = 0\n",
    "        \n",
    "        a1 = np.hstack((np.zeros(len(X)), np.ones(len(X))))\n",
    "        a1 = np.hstack((a1, np.zeros(len(X))))\n",
    "        a1 = np.hstack((a1, np.ones(len(X))))\n",
    "        b1 = 0\n",
    "        \n",
    "        a2 = np.hstack((np.ones(len(X)), np.zeros(len(X))))\n",
    "        a2 = np.hstack((a2, np.ones(len(X))))\n",
    "        a2 = np.hstack((a2, np.zeros(len(X))))\n",
    "        b2 = 0\n",
    "        \n",
    "        a = np.vstack((a0,a1))\n",
    "        a = np.vstack((a,a2))\n",
    "        \n",
    "        b = np.vstack((b0,b1))\n",
    "        b = np.vstack((b,b2))\n",
    "        \n",
    "        P = matrix(p, tc='d')\n",
    "        q = matrix(q, tc='d')\n",
    "        G = matrix(g, tc='d')\n",
    "        h = matrix(h, tc='d')\n",
    "        A = matrix(a, tc='d')\n",
    "        b = matrix(b, tc='d')\n",
    "        \n",
    "        \n",
    "        solvers.options['show_progress'] = False\n",
    "        sol = solvers.qp(P, q, G, h, A, b)\n",
    "        alphas_alphastars_deltas_deltastars = np.array(sol['x'])\n",
    "        self.alphas = np.asarray(alphas_alphastars_deltas_deltastars[:len(X)])\n",
    "        self.alphastars = np.asarray(alphas_alphastars_deltas_deltastars[len(X):2*len(X)])\n",
    "        self.deltas = np.asarray(alphas_alphastars_deltas_deltastars[2*len(X):3*len(X)])\n",
    "        self.deltastars = np.asarray(alphas_alphastars_deltas_deltastars[3*len(X):])\n",
    "        \n",
    "        self.bias = self.get_bias()\n",
    "        #print(self.get_w())\n",
    "        \n",
    "    def get_w(self): # Not used as weight in cany calculations - just used to visualise weights associated with each feature\n",
    "        running_total = np.zeros_like(self.training_X[0])\n",
    "        for i in range(len(self.training_X)):\n",
    "            running_total += (self.alphastars[i] - self.alphas[i]) * self.training_X[i]\n",
    "        return running_total\n",
    "            \n",
    "        \n",
    "    def get_neg_bias(self):\n",
    "        running_total = 0\n",
    "        num_sv = 0\n",
    "        for i in range(len(self.training_X)):\n",
    "            if (self.alphas[i] > 1e-8 and self.deltas[i] > -self.C):\n",
    "                running_total += self.Y[i] - self.predict_wo_bias(self.training_X[i]) - self.epsilon\n",
    "                num_sv +=1\n",
    "        return running_total / num_sv if num_sv > 0 else running_total\n",
    "                \n",
    "    def get_pos_bias(self):\n",
    "        running_total = 0\n",
    "        num_sv = 0\n",
    "        for i in range(len(self.training_X)):\n",
    "            if (self.alphastars[i] > 1e-8 and self.deltastars[i] > -self.C):\n",
    "                running_total += self.Y[i] - self.predict_wo_bias(self.training_X[i]) + self.epsilon\n",
    "                num_sv +=1\n",
    "        return running_total / num_sv if num_sv > 0 else running_total\n",
    "    \n",
    "    def get_bias(self):\n",
    "        return (self.get_pos_bias() + self.get_neg_bias())/2\n",
    "        \n",
    "    def gram(self, a, b, kern, sig):\n",
    "        phi = np.zeros((len(a), len(a)))\n",
    "        for i in range(len(a)):\n",
    "            for j in range(len(a)):\n",
    "                phi[i,j] = kern(a[i], b[j], sig)\n",
    "        return phi\n",
    "    \n",
    "    def predict_wo_bias(self, x):\n",
    "        y = 0\n",
    "        for i in range(len(self.training_X)):\n",
    "            y += (self.alphastars[i] - self.alphas[i]) * self.kern_x(self.training_X[i], x, self.sigma)\n",
    "        return y\n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        y = 0\n",
    "        for i in range(len(self.training_X)):\n",
    "            y += (self.alphastars[i] - self.alphas[i]) * self.kern_x(self.training_X[i], x, self.sigma)\n",
    "        return y + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_performance_svr_plus(train_X, train_Xs, train_Y, test_X, test_Y, C, epsilon, gamma, kern):\n",
    "    model = SVR()\n",
    "    model.train(train_X, train_Xs, train_Y, C, epsilon, gamma, kern)\n",
    "    discrepancy = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in range(len(test_X)):\n",
    "        p = model.predict(test_X[i])\n",
    "        y_true.append(test_Y[i])\n",
    "        y_pred.append(p)\n",
    "        discrepancy += 0.5*((model.predict(test_X[i]) - test_Y[i])**2)\n",
    "    pred = np.asarray(y_pred).reshape(1,-1)\n",
    "    save = np.concatenate((test_X, pred.T), axis=1)\n",
    "    save = np.concatenate((save, test_Y), axis=1)\n",
    "    np.savetxt(\"SVR+_output.csv\", save, delimiter=\",\")\n",
    "    return np.sqrt(discrepancy/len(test_X)), r2_score(y_true, y_pred), C, epsilon, gamma, kern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's check that we can overfit the model. We'll test the model with the training data. Massively penalize not going through each data point and make epsilon (the window of error) very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated (singular KKT matrix).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.2642103]),\n",
       " 0.99999286264650744,\n",
       " 10000000000.0,\n",
       " 1,\n",
       " 1.0,\n",
       " <__main__.Gaussian at 0x108449908>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance_svr_plus(train_x[:,:], train_x[:,:], train_y, train_x[:,:], train_y, 1e+10, 1, 1e+0, Gaussian())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, that looks as though it works as we'd expect. Don't worry about the singular KKT matrix, we've got some very unusual conditions that we're trying to make work. The second line is the weights assiciated with each feature, we'll come back to them with the LUFe idea. But for now let's go about making improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_svr_plus(X, X_star, Y, Cs, epsilons, gammas, kerns, folds=5):\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "    outcomes = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        X_star_train, X_star_test = X_star[train_index], X_star[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        ikf = KFold(n_splits=folds, shuffle=True)\n",
    "        ikf.get_n_splits(X_train)\n",
    "        inner_outcomes = []\n",
    "        for inner_train_index, inner_test_index in ikf.split(X_train):\n",
    "            inner_X_train, inner_X_test = X_train[inner_train_index], X_train[inner_test_index]\n",
    "            inner_X_star_train, inner_X_star_test = X_star_train[inner_train_index], X_star_train[inner_test_index]\n",
    "            inner_Y_train, inner_Y_test = Y_train[inner_train_index], Y_train[inner_test_index]\n",
    "            inner_results = [test_performance_svr_plus(inner_X_train, inner_X_star_train, inner_Y_train, inner_X_test, inner_Y_test, C, epsilon, gamma, kern) for C in Cs for epsilon in epsilons for gamma in gammas for kern in kerns]\n",
    "            inner_outcomes = inner_outcomes + [(ir[0], ir[1], ir[2], ir[3], ir[4], ir[5]) for ir in inner_results]\n",
    "        means_of_inner = [(np.mean([io[0] for io in inner_outcomes if io[2] == c and io[3] == e and io[4] == g and io[5] == k]), \n",
    "                          np.mean([io[1] for io in inner_outcomes if io[2] == c and io[3] == e and io[4] == g and io[5] == k]), c, e, g, k) for c in Cs for e in epsilons for g in gammas for k in kerns]\n",
    "        best_inner = sorted(means_of_inner, key=itemgetter(0))\n",
    "        best_inner = best_inner[0]\n",
    "        outcomes.append(test_performance_svr_plus(X_train, X_star_train, Y_train, X_test, Y_test, best_inner[2], best_inner[3], best_inner[4], best_inner[5]))\n",
    "    return (np.mean([(outcome[0]) for outcome in outcomes]), np.mean([(outcome[1]) for outcome in outcomes]), best_inner[2], best_inner[3], best_inner[4], best_inner[5].name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102.12350867733528, -0.075080517886867981, 1, 1, 1, 'Gaussian')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate_svr_plus(train_x[:50,:], train_x[:50,:], train_y[:50,:], [0.5, 1], [0.5, 1], [0.5, 1], [Gaussian(), Linear()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
